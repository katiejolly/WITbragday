---
title: "How Women in Tech Talk About Themselves on Twitter"
author: Katie Jolly
output: 
  slidy_presentation:
    theme: spacelab
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r include = FALSE}
library(rtweet)
library(dplyr)
library(lubridate)
library(viridis)
library(ggplot2)
library(ggthemes)
library(tm)
library(readr)
library(tm)
library(topicmodels)
library(wordcloud)
library(SentimentAnalysis)
library(stringi)
library(highcharter)
library(stringr)
library(stm)

wit_bragday <- read_csv("https://raw.githubusercontent.com/katiejolly/WITbragday/master/wit_bragday.csv") %>% 
  filter(is_retweet == FALSE)
```

## The problem, and a solution

We often hear in the news about how professional women talk about themselves at work. But, we don't always hear much of a solution. One hashtag in August aimed to change that. 


![](alice.png)


## Exploratory analysis


```{r include = FALSE}
wit_bragday$created_at_clean <- as.POSIXct(wit_bragday$created_at, tz = "GMT")

wit_bragday$created_at_local <- format(wit_bragday$created_at_clean, tz = "America/New_York", usetz = TRUE)

# formatting the dates differently 

times <- ymd_hms(wit_bragday$created_at_local, quiet = TRUE)

times_df <- data.frame(wkday = (weekdays(as.Date(times))),
          hour = format(times, "%H"),
          tweet_id = wit_bragday$status_id)

# group by time

times_grouped <- times_df %>% group_by(wkday, hour) %>% summarize(n = n())

# fix factor levels

times_grouped$wkday <- factor(times_grouped$wkday, levels =c("Friday", "Saturday", "Sunday", "Monday", "Tuesday"))

times_grouped$wkday <- with(times_grouped, factor(wkday, levels = rev(levels(wkday))))
```



```{r}
hchart(times_grouped, type = "heatmap", hcaes(x = hour, y = wkday, value = n), name = "tweets")
```

## Frequent terms

```{r include = FALSE}
# create a corpus of text
myCorpus <- Corpus(VectorSource( wit_bragday$text))

# remove extaneous characters
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
myCorpus <- tm_map(myCorpus, content_transformer(removeNumPunct))

# convert all to lowercase
myCorpus <- tm_map(myCorpus, content_transformer(tolower))

# remove whitespace
myCorpus <- tm_map(myCorpus, stripWhitespace)

# remove stopwords
myStopwords <- c(stopwords('english'),
"witbragday", "amp", "hashtag", "women", "tech")
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)

# a copy for later
myCorpusCopy <- myCorpus

# build term document matrix
tdm <- TermDocumentMatrix(myCorpus,
                          control = list(wordLengths = c(1, Inf)))

# view term document matrix
tdm

# find frequent terms, n = 50

freq_terms <- findFreqTerms(tdm, lowfreq = 50)

term_freq <- rowSums(as.matrix(tdm))
term_freq <- subset(term_freq, term_freq >= 50)

frequencies <- data.frame(term = names(term_freq), freq = term_freq)

high_freq <- subset(frequencies, freq >= 175)

high_freq$term <- factor(high_freq$term, levels = high_freq[order(high_freq$freq, decreasing = T),]$term)

```


## Sentiment analysis

```{r}
wit_bragday$text_usable <- gsub("[^[:alpha:][:space:]]*", "", wit_bragday$text)
sentiments <- analyzeSentiment(as.character(wit_bragday$text_usable)) 

hchart(density(sentiments$SentimentGI), type = "area", color = "#B71C1C", name = "Density") %>%
  hc_xAxis(title = list(text = "Sentiment"))
```

## Topic modeling

```{r cache = TRUE}
wit_stm_data <- wit_bragday %>%
  select(c(text, text_usable, favorite_count, retweet_count))
processed <- textProcessor(wit_stm_data$text_usable, metadata = wit_stm_data)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
vocab <- out$vocab
meta <-out$meta

witmodel <- stm(documents = out$documents, vocab = out$vocab,
K = 7, prevalence =~ favorite_count * retweet_count,
max.em.its = 200, data = out$meta,
init.type = "Spectral")


plot(witmodel, type = "summary", xlim = c(0, .3))
```
